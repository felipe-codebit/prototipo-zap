import { simpleNlpService } from './simple-nlp';
import { OpenAIService } from './openai';
import { ConversationContextManager } from './conversation-context';
import { ChatLogger } from './logger';
import { Intent, PlanoAulaData, PlanejamentoSemanalData } from '@/types';

export class MessageProcessor {
  static async processMessage(message: string, sessionId: string): Promise<string> {
    try {
      const msg = message.toLowerCase().trim();
      
      // Verifica√ß√£o priorit√°ria para comando "sair" - deve funcionar em qualquer momento
      if (['sair', 'cancelar', 'parar', 'reiniciar', 'recome√ßar', 'volta', 'voltar'].includes(msg) ||
          msg.includes('come√ßar de novo') || msg.includes('come√ßar denovo') ||
          msg.includes('sair daqui') || msg.includes('cancelar tudo')) {
        return this.handleSairIntent(sessionId);
      }

      // Verifica√ß√£o priorit√°ria para gera√ß√£o de PDF - DEVE vir antes da an√°lise de inten√ß√£o
      if (this.isPDFRequest(msg)) {
        console.log('üìÑ Solicita√ß√£o de PDF detectada:', message);
        console.log('üìÑ Interrompendo processamento normal para gerar PDF');
        return this.handlePDFRequest(sessionId, message);
      }

      const currentContext = ConversationContextManager.getContext(sessionId);
      console.log('üöÄ [DEBUG] processMessage iniciado:', {
        message: message.substring(0, 50),
        sessionId: sessionId.substring(0, 8),
        currentIntent: currentContext.currentIntent,
        hasCollectedData: Object.keys(currentContext.collectedData).length > 0
      });



      const currentIntent = currentContext.currentIntent;

      // Analisar inten√ß√£o
      const intentAnalysis = await simpleNlpService.analyzeIntent(message, sessionId);

      // Decidir qual inten√ß√£o usar: manter atual se estivermos coletando dados ou usar nova se clara
      let finalIntent = intentAnalysis.intent;
      let finalConfidence = intentAnalysis.confidence;

      // Se j√° temos uma inten√ß√£o ativa e estamos coletando dados, manter a inten√ß√£o atual
      // a menos que a nova inten√ß√£o seja muito clara (confian√ßa > 0.8)
      if (currentIntent &&
          currentIntent !== 'saudacao' &&
          currentIntent !== 'despedida' &&
          currentIntent !== 'unclear' &&
          Object.keys(currentContext.collectedData).length > 0) {

        // Se a nova inten√ß√£o n√£o √© muito clara, manter a atual
        if (intentAnalysis.confidence < 0.8 || intentAnalysis.intent === 'unclear') {
          finalIntent = currentIntent;
          finalConfidence = currentContext.intentConfidence;

          ChatLogger.logIntent(sessionId, `${finalIntent} (mantida)`, finalConfidence, message);
        }
      }

      // Atualizar contexto
      ConversationContextManager.updateIntent(sessionId, finalIntent, finalConfidence);



      // Gerar resposta baseada na inten√ß√£o
      return await this.generateResponseByIntent(message, sessionId, finalIntent);

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { message });
      return 'Desculpe, ocorreu um erro ao processar sua mensagem. Pode tentar novamente?';
    }
  }





  private static async extractAdditionalInfo(sessionId: string, intent: Intent) {
    const recentMessages = ConversationContextManager.getRecentUserMessages(sessionId, 3);
    const latestMessage = recentMessages[recentMessages.length - 1];
    const currentContext = ConversationContextManager.getContext(sessionId);

    if (!latestMessage) return;

    // Usar a inten√ß√£o atual se estivermos coletando informa√ß√µes do usu√°rio
    const effectiveIntent = (currentContext.currentIntent &&
                           Object.keys(currentContext.collectedData).length > 0)
                           ? currentContext.currentIntent
                           : intent;

    // Usar LLM para extrair dados de forma inteligente
    if (effectiveIntent === 'plano_aula' || effectiveIntent === 'planejamento_semanal') {
      const extractedData = await OpenAIService.extractDataFromMessage(
        latestMessage,
        effectiveIntent,
        currentContext.collectedData,
        sessionId
      );

      // Atualizar dados coletados com o que foi extra√≠do
      for (const [key, value] of Object.entries(extractedData)) {
        if (value) {
          ConversationContextManager.updateCollectedData(sessionId, key, value);
        }
      }
    }
  }

  // Fun√ß√µes antigas de extra√ß√£o baseadas em keywords foram removidas
  // Agora usamos extractDataFromMessage da OpenAIService que usa LLM

  /**
   * Infere o que o usu√°rio quer continuar com base no hist√≥rico da conversa
   */
  private static async inferContinuationIntent(
    conversationHistory: Array<{ sender: string; text: string }>,
    sessionId: string
  ): Promise<Intent | null> {
    try {
      const recentHistory = conversationHistory.slice(-6).map(msg =>
        `${msg.sender === 'user' ? 'Professor' : 'Ane'}: ${msg.text}`
      ).join('\n');

      const prompt = `Analise o hist√≥rico da conversa e identifique o que o professor quer continuar fazendo.

HIST√ìRICO:
${recentHistory}

O professor disse que quer "continuar". Com base no contexto, o que ele provavelmente quer fazer?

OP√á√ïES:
- plano_aula: Quer criar/continuar criando um plano de aula
- planejamento_semanal: Quer criar/continuar um planejamento semanal
- tira_duvidas: Quer fazer perguntas/tirar d√∫vidas
- null: N√£o h√° contexto claro do que continuar

Analise:
- O que a Ane sugeriu nas √∫ltimas mensagens?
- Qual era o t√≥pico da conversa?
- Houve algum plano/tarefa mencionado?

Retorne APENAS JSON: {"intent": "nome_ou_null", "confidence": 0.0}`;

      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Voc√™ √© um analisador de contexto conversacional.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 100,
        temperature: 0.1
      });

      const result = response.choices[0]?.message?.content?.trim();
      if (!result) return null;

      const parsed = JSON.parse(result);
      if (parsed.confidence >= 0.7 && parsed.intent !== 'null') {
        return parsed.intent as Intent;
      }

      return null;
    } catch (error) {
      console.error('Erro ao inferir inten√ß√£o de continua√ß√£o:', error);
      return null;
    }
  }

  private static async generateResponseByIntent(message: string, sessionId: string, intent: Intent): Promise<string> {
    switch (intent) {
      case 'plano_aula':
        return this.handlePlanoAulaIntent(sessionId);

      case 'planejamento_semanal':
        return this.handlePlanejamentoSemanalIntent(sessionId);

      case 'tira_duvidas':
        return OpenAIService.generateResponse(message, sessionId);

      case 'saudacao':
        return await this.handleSaudacao(message, sessionId);

      case 'despedida':
        return this.handleDespedida(sessionId);

      case 'sair':
        return this.handleSairIntent(sessionId);

      case 'continuar':
        return this.handleContinuarIntent(sessionId, message);

      case 'revisar_plano':
        return this.handleRevisarPlanoIntent(sessionId, message);

      case 'reflexao_pedagogica':
        return this.handleReflexaoPedagogicaIntent(sessionId, message);

      default:
        return this.handleUnclearIntent(message, sessionId);
    }
  }

  private static async handleRevisarPlanoIntent(sessionId: string, message: string): Promise<string> {
    try {
      // Verificar se h√° um plano anterior para revisar
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      
      if (!persistentContent?.lastPlanoContent) {
        return "N√£o encontrei um plano de aula anterior para revisar. Voc√™ precisa primeiro gerar um plano de aula antes de poder revis√°-lo. Gostaria de criar um novo plano?";
      }

      // Extrair informa√ß√µes de altera√ß√£o da mensagem
      const alteracoes = await this.extractAlteracoesPlano(message, sessionId);
      
      if (Object.keys(alteracoes).length === 0) {
        return "Entendi que voc√™ quer revisar o plano, mas n√£o consegui identificar o que deseja alterar. Voc√™ pode especificar se quer mudar:\n\n‚Ä¢ A dificuldade (f√°cil, m√©dio, dif√≠cil)\n‚Ä¢ O ano escolar\n‚Ä¢ O tema/habilidade BNCC\n\nPor exemplo: 'alterar a dificuldade para f√°cil' ou 'mudar para 5¬∫ ano'";
      }

      // Obter dados do plano original
      const dadosOriginais = ConversationContextManager.getCollectedData(sessionId) as PlanoAulaData;
      
      // Aplicar altera√ß√µes
      const novosDados = { ...dadosOriginais, ...alteracoes };
      
      // Atualizar dados coletados
      Object.keys(alteracoes).forEach(key => {
        ConversationContextManager.updateCollectedData(sessionId, key, alteracoes[key]);
      });

      // Gerar novo plano com as altera√ß√µes
      const novoPlano = await OpenAIService.generatePlanoAula(novosDados, sessionId);
      
      // Preservar o novo conte√∫do
      const planoContent = this.extractPlanoContent(novoPlano);
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);

      // Gerar resposta contextual
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'plano_revisado',
        {
          collectedData: { ...novosDados, alteracoes: alteracoes },
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // Resetar contexto mantendo hist√≥rico e dados do plano
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanoContent']);

      return `${contextualResponse}\n\n${novoPlano}\n\n‚úÖ Plano revisado com sucesso! As altera√ß√µes foram aplicadas.`;

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { context: 'revisar_plano', message });
      return "Desculpe, ocorreu um erro ao revisar o plano. Tente novamente ou digite 'sair' para reiniciar.";
    }
  }

  private static async handleReflexaoPedagogicaIntent(sessionId: string, message: string): Promise<string> {
    try {
      // Verificar se h√° um plano anterior para refer√™ncia
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;
      
      if (!hasPreviousPlan) {
        return "Que legal que voc√™ quer refletir sobre a pr√°tica pedag√≥gica! üí≠\n\nPara te ajudar melhor, seria interessante ter um plano de aula como refer√™ncia. Voc√™ gostaria de criar um plano primeiro ou prefere conversar sobre algum aspecto espec√≠fico da sua pr√°tica?";
      }

      // Gerar prompt de reflex√£o pedag√≥gica amig√°vel
      const planoData = ConversationContextManager.getCollectedData(sessionId).lastPlanoData as PlanoAulaData;
      const reflectionPrompt = await this.generateReflectionPrompt(planoData, sessionId);

      return reflectionPrompt;

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { context: 'reflexao_pedagogica', message });
      return "Desculpe, ocorreu um erro ao processar sua reflex√£o. Tente novamente ou digite 'sair' para reiniciar.";
    }
  }

  /**
   * Gera um prompt amig√°vel para reflex√£o pedag√≥gica baseado em exemplos passados
   */
  private static async generateReflectionPrompt(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `Voc√™ √© a ANE, assistente pedag√≥gica. O professor quer refletir sobre sua pr√°tica pedag√≥gica.

Dados do plano de refer√™ncia:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- N√≠vel: ${data.nivelDificuldade || 'm√©dio'}

Crie um prompt de reflex√£o pedag√≥gica que:
1. Seja acolhedor e encorajador
2. Instigue o professor a pensar profundamente sobre sua pr√°tica
3. Use exemplos espec√≠ficos do plano como base
4. Fa√ßa perguntas que extraiam feedback valioso
5. Seja conversacional e natural
6. Ofere√ßa diferentes √¢ngulos de reflex√£o

O prompt deve ser como uma conversa entre colegas, n√£o um question√°rio formal. Use o tema e ano do plano para personalizar as perguntas.

Exemplo de tom:
"Que bom que voc√™ quer refletir sobre sua pr√°tica! üí≠ 

Vejo que voc√™ trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experi√™ncia? Me conta:

üéØ **O que mais te surpreendeu** durante a implementa√ß√£o desse plano? Houve algum momento em que voc√™ pensou 'nossa, n√£o esperava que fosse assim'?

üë• **Como foi a rea√ß√£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que voc√™ esperava? O que isso te ensinou?

üí° **Que insights voc√™ teve** sobre como seus alunos aprendem melhor? Descobriu alguma estrat√©gia que funcionou especialmente bem?

üîÑ **Se fosse fazer de novo**, o que voc√™ mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experi√™ncia! Conte-me o que mais te marcou nessa aula. üòä"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Voc√™ √© a ANE, uma assistente pedag√≥gica que ama ouvir e aprender com as experi√™ncias dos professores.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 400,
        temperature: 0.8
      });

      return response.choices[0]?.message?.content || 
        `Que bom que voc√™ quer refletir sobre sua pr√°tica! üí≠ 

Vejo que voc√™ trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experi√™ncia? Me conta:

üéØ **O que mais te surpreendeu** durante a implementa√ß√£o desse plano? Houve algum momento em que voc√™ pensou 'nossa, n√£o esperava que fosse assim'?

üë• **Como foi a rea√ß√£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que voc√™ esperava? O que isso te ensinou?

üí° **Que insights voc√™ teve** sobre como seus alunos aprendem melhor? Descobriu alguma estrat√©gia que funcionou especialmente bem?

üîÑ **Se fosse fazer de novo**, o que voc√™ mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experi√™ncia! Conte-me o que mais te marcou nessa aula. üòä`;

    } catch (error) {
      console.error('‚ùå Erro ao gerar prompt de reflex√£o:', error);
      return `Que bom que voc√™ quer refletir sobre sua pr√°tica! üí≠ 

Vejo que voc√™ trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experi√™ncia? Me conta:

üéØ **O que mais te surpreendeu** durante a implementa√ß√£o desse plano? Houve algum momento em que voc√™ pensou 'nossa, n√£o esperava que fosse assim'?

üë• **Como foi a rea√ß√£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que voc√™ esperava? O que isso te ensinou?

üí° **Que insights voc√™ teve** sobre como seus alunos aprendem melhor? Descobriu alguma estrat√©gia que funcionou especialmente bem?

üîÑ **Se fosse fazer de novo**, o que voc√™ mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experi√™ncia! Conte-me o que mais te marcou nessa aula. üòä`;
    }
  }

  private static async handlePlanoAulaIntent(sessionId: string): Promise<string> {
    // Extrair informa√ß√µes da mensagem atual no contexto da inten√ß√£o
    await this.extractAdditionalInfo(sessionId, 'plano_aula');

    const missingData = ConversationContextManager.getMissingDataForPlanoAula(sessionId);

    if (missingData.length === 0) {
      // Todos os dados coletados, gerar plano de aula
      const data = ConversationContextManager.getCollectedData(sessionId) as PlanoAulaData;
      const planoAula = await OpenAIService.generatePlanoAula(data, sessionId);

      // Gerar resposta contextual e conversacional
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'plano_aula_completo',
        {
          collectedData: data,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // Adicionar mensagem de continuidade conversacional
      const continuationMessage = await this.generatePostPlanContinuationMessage(data, sessionId);

      // IMPORTANTE: Preservar o conte√∫do do plano para gera√ß√£o de PDF posterior
      const planoContent = this.extractPlanoContent(planoAula);
      if (planoContent) {
        ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);
        // Tamb√©m preservar os dados do plano para refer√™ncia futura
        ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoData', data);
      }

      // Limpar contexto mas preservar o conte√∫do do plano e dados
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanoContent', 'lastPlanoData']);

      return `${contextualResponse}\n\n${planoAula}\n\n${continuationMessage}`;
    } else {
      // Ainda faltam dados, perguntar especificamente
      return await this.askForMissingPlanoAulaData(missingData, sessionId);
    }
  }

  private static async handlePlanejamentoSemanalIntent(sessionId: string): Promise<string> {
    // Extrair informa√ß√µes da mensagem atual no contexto da inten√ß√£o
    await this.extractAdditionalInfo(sessionId, 'planejamento_semanal');

    const missingData = ConversationContextManager.getMissingDataForPlanejamentoSemanal(sessionId);

    if (missingData.length === 0) {
      // Todos os dados coletados, gerar planejamento semanal
      const data = ConversationContextManager.getCollectedData(sessionId) as PlanejamentoSemanalData;
      const planejamento = await OpenAIService.generatePlanejamentoSemanal(data, sessionId);

      // Gerar resposta contextual e conversacional
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'planejamento_semanal_completo',
        {
          collectedData: data,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // IMPORTANTE: Preservar o conte√∫do do planejamento para gera√ß√£o de PDF posterior
      const planejamentoContent = planejamento; // Para planejamento semanal, usar o conte√∫do completo
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanejamentoContent', planejamentoContent);
      // Tamb√©m preservar os dados do planejamento para refer√™ncia futura
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanejamentoData', data);

      // Limpar contexto mas preservar o conte√∫do do planejamento e dados
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanejamentoContent', 'lastPlanejamentoData']);

      return `${contextualResponse}\n\n${planejamento}`;
    } else {
      // Ainda faltam dados
      return await this.askForMissingPlanejamentoSemanalData(missingData, sessionId);
    }
  }

  private static async askForMissingPlanoAulaData(missingData: string[], sessionId: string): Promise<string> {
    const collectedData = ConversationContextManager.getCollectedData(sessionId);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Verificar se o usu√°rio est√° pedindo sugest√µes de tema
    const lastUserMessage = conversationHistory
      .filter(msg => msg.sender === 'user')
      .pop()?.text.toLowerCase() || '';

    const isAskingForSuggestions = lastUserMessage.includes('sugira') || 
                                  lastUserMessage.includes('sugest√£o') || 
                                  lastUserMessage.includes('sugest√µes') ||
                                  lastUserMessage.includes('tanto faz') ||
                                  lastUserMessage.includes('qualquer') ||
                                  lastUserMessage.includes('n√£o sei') ||
                                  lastUserMessage.includes('nao sei') ||
                                  lastUserMessage.includes('me ajuda') ||
                                  lastUserMessage.includes('me ajuda a escolher');

    if (isAskingForSuggestions && missingData.includes('tema ou habilidade BNCC')) {
      // Gerar sugest√µes de temas baseadas no ano escolar
      const ano = collectedData.ano || '5¬∫ ano'; // Default para 5¬∫ ano se n√£o especificado
      return await this.generateThemeSuggestions(ano, sessionId);
    }

    // Gera a pergunta conversacional usando a LLM para todos os dados faltantes
    const question = await OpenAIService.generateConversationalQuestion(
      missingData.join(', '), // Passa todos os campos faltantes
      collectedData,
      conversationHistory.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text
      })),
      sessionId
    );

    return question;
  }

  private static async askForMissingPlanejamentoSemanalData(missingData: string[], sessionId: string): Promise<string> {
    const collectedData = ConversationContextManager.getCollectedData(sessionId);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Gera a pergunta conversacional usando a LLM para todos os dados faltantes
    const question = await OpenAIService.generateConversationalQuestion(
      missingData.join(', '), // Passa todos os campos faltantes
      collectedData,
      conversationHistory.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text
      })),
      sessionId
    );

    return question;
  }

  private static async handleSaudacao(message: string, sessionId: string): Promise<string> {
    console.log('üëã [DEBUG] Processando sauda√ß√£o com LLM');

    try {
      const { OpenAIService } = await import('./openai');
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      // Verificar se h√° um plano anterior para refer√™ncia contextual
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;
      
      let contextInfo = '';
      if (hasPreviousPlan) {
        contextInfo = `
CONTEXTO IMPORTANTE: O professor j√° tem um plano anterior gerado nesta conversa. 
Se ele fizer uma sauda√ß√£o simples, mencione que pode continuar trabalhando com o plano anterior ou criar um novo.
Se ele perguntar sobre funcionalidades, inclua op√ß√µes como "gerar PDF do plano anterior" ou "ajustar o plano".
`;
      }

      const promptParaSaudacao = `
A mensagem do professor: "${message}"

${contextInfo}

‚û°Ô∏è Regras de comportamento:

1. SEMPRE reconhe√ßa sauda√ß√µes e "small talk" (ex.: "oi, tudo bem?", "bom dia!", "tudo certo?", "como voc√™ pode ajudar?") antes de qualquer instru√ß√£o, de forma natural e acolhedora.

2. Sua apresenta√ß√£o deve sempre usar como base a mensagem abaixo, adaptando a linguagem para soar natural e pr√≥xima do professor:
"Oi, eu sou a ANE, sua assistente pedag√≥gica. üë©üèΩ‚Äçüè´üí°  
Quero te mostrar rapidinho como posso te ajudar por aqui, tudo bem?"

3. SEMPRE explique o que voc√™ consegue fazer, mesmo quando houver uma solicita√ß√£o espec√≠fica.
Liste claramente suas principais fun√ß√µes:
üëâüèΩ Crio planos de aula
üëâüèΩ Trago ideias de metodologias e atividades
üëâüèΩ Ajudo na reflex√£o sobre suas pr√°ticas pedag√≥gicas
üí¨ Para te ajudar preciso saber o ano e tema ou habilidade da sua aula

4. Se o professor j√° trouxer uma solicita√ß√£o, adapte a explica√ß√£o acima ao contexto e incentive que ele d√™ mais detalhes.

5. SEMPRE finalize mostrando que √© um prazer ajudar.

${hasPreviousPlan ? `
6. IMPORTANTE: Se h√° um plano anterior, mencione as op√ß√µes de continuar com ele:
- Gerar PDF do plano anterior
- Ajustar o plano anterior
- Criar um novo plano
` : ''}

EXEMPLOS DE RESPOSTAS:

Se o professor mandar apenas "Oi, tudo bem?":
"Oi, tudo bem? Eu sou a ANE, sua assistente pedag√≥gica üë©üèΩ‚Äçüè´üí°.
Quero te mostrar rapidinho como posso te ajudar por aqui.
üëâüèΩ Crio planos de aula
üëâüèΩ Trago ideias de metodologias e atividades
üëâüèΩ Ajudo na reflex√£o sobre suas pr√°ticas pedag√≥gicas
üí¨ Para come√ßar, me conta o ano e o tema ou habilidade que voc√™ quer trabalhar?
Vai ser um prazer te ajudar!"

Se o professor mandar "Como voc√™ pode ajudar?" ou "O que voc√™ faz?":
"Oi! Eu sou a ANE, sua assistente pedag√≥gica üë©üèΩ‚Äçüè´üí°.
Que bom voc√™ perguntar! Vou te mostrar rapidinho como posso te ajudar por aqui.
üëâüèΩ Crio planos de aula
üëâüèΩ Trago ideias de metodologias e atividades
üëâüèΩ Ajudo na reflex√£o sobre suas pr√°ticas pedag√≥gicas
üí¨ Para come√ßar, me conta o ano e o tema ou habilidade que voc√™ quer trabalhar?
Vai ser um prazer te ajudar!"

Se o professor mandar "Oi, bom dia, me ajuda a planejar uma aula sobre fra√ß√µes para o 6¬∫ ano?":
"Oi, bom dia! Eu sou a ANE, sua assistente pedag√≥gica üë©üèΩ‚Äçüè´üí°.
Que √≥timo voc√™ j√° trazer seu pedido! Antes de come√ßarmos, deixa eu te contar rapidinho como posso te ajudar:
üëâüèΩ Crio planos de aula
üëâüèΩ Trago ideias de metodologias e atividades
üëâüèΩ Ajudo na reflex√£o sobre suas pr√°ticas pedag√≥gicas
üí¨ Voc√™ mencionou fra√ß√µes para o 6¬∫ ano. Quer que eu crie um plano completo com atividades ou prefere s√≥ ideias de metodologias para essa habilidade?"
`;

      const response = await client.chat.completions.create({
        model: 'gpt-4-turbo',
        messages: [
          { role: 'system', content: promptParaSaudacao },
          { role: 'user', content: message }
        ],
        max_tokens: 300,
        temperature: 0.7
      });

      const botResponse = response.choices[0]?.message?.content ||
        `Oi! Eu sou a ANE, sua assistente pedag√≥gica. Como posso te ajudar?`;

      console.log('‚úÖ [DEBUG] Resposta LLM para sauda√ß√£o gerada');
      
      // Adicionar marcador para v√≠deo de sauda√ß√£o
      return `[VIDEO_SAUDACAO]${botResponse}`;

    } catch (error) {
      console.error('‚ùå [DEBUG] Erro no LLM para sauda√ß√£o:', error);
      // Fallback em caso de erro
      return `[VIDEO_SAUDACAO]Oi! Eu sou a ANE, sua assistente pedag√≥gica. üë©üèΩ‚Äçüè´üí° Como posso te ajudar hoje?`;
    }
  }

  private static async handleDespedida(sessionId: string): Promise<string> {
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    const response = await OpenAIService.generateContextualResponse(
      'despedida',
      {
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );

    ConversationContextManager.clearContext(sessionId);
    return response;
  }

  private static async handleSairIntent(sessionId: string): Promise<string> {
    // Registrar a mensagem do usu√°rio no hist√≥rico antes de resetar o contexto
    ConversationContextManager.addMessage(sessionId, {
      id: `user_${Date.now()}`,
      text: '[Usu√°rio solicitou reiniciar conversa]',
      sender: 'user',
      timestamp: new Date(),
      type: 'text'
    });

    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    const response = await OpenAIService.generateContextualResponse(
      'reiniciar',
      {
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );

    ConversationContextManager.resetContextKeepingHistory(sessionId);

    // Registrar a resposta do bot no hist√≥rico
    ConversationContextManager.addMessage(sessionId, {
      id: `bot_${Date.now()}`,
      text: response,
      sender: 'bot',
      timestamp: new Date(),
      type: 'text'
    });

    return response;
  }

  /**
   * Verifica se a mensagem √© uma solicita√ß√£o de PDF
   */
  private static isPDFRequest(message: string): boolean {
    const msg = message.toLowerCase().trim();
    
    const pdfKeywords = [
      'gerar pdf',
      'gerar em pdf',
      'fazer pdf',
      'criar pdf',
      'baixar pdf',
      'exportar pdf',
      'pdf do plano',
      'plano em pdf',
      'baixar plano',
      'exportar plano',
      'compartilhar pdf',
      'enviar pdf',
      'quero pdf',
      'preciso pdf',
      'fazer download',
      'baixar arquivo',
      'exportar arquivo',
      'quero gerar o pdf',
      'quero gerar pdf',
      'gerar o pdf',
      'fazer o pdf',
      'criar o pdf',
      'baixar o pdf',
      'gere o pdf',
      'gera o pdf',
      'gere pdf',
      'gera pdf',
      'gera o pdf',
      'faz o pdf',
      'cria o pdf',
      'baixa o pdf',
      'exporta o pdf',
      'compartilha o pdf',
      'envia o pdf',
      'quero o pdf',
      'preciso o pdf',
      'faz o pdf',
      'cria o pdf',
      'baixa o pdf',
      'exporta o pdf',
      'compartilha o pdf',
      'envia o pdf',
      'quero o pdf',
      'preciso o pdf',
      'faz o pdf',
      'quero em pdf',
      // Termos coloquiais para solicita√ß√£o de PDF
      'manda o plano',
      'manda o pdf',
      'manda pdf',
      'manda plano',
      'envia o plano',
      'envia plano',
      'me manda o plano',
      'me manda o pdf',
      'me manda pdf',
      'me manda plano',
      'me envia o plano',
      'me envia o pdf',
      'me envia pdf',
      'me envia plano',
      'pode mandar o plano',
      'pode mandar o pdf',
      'pode mandar pdf',
      'pode mandar plano',
      'pode enviar o plano',
      'pode enviar o pdf',
      'pode enviar pdf',
      'pode enviar plano',
      'manda a√≠ o plano',
      'manda a√≠ o pdf',
      'manda a√≠ pdf',
      'manda a√≠ plano',
      'envia a√≠ o plano',
      'envia a√≠ o pdf',
      'envia a√≠ pdf',
      'envia a√≠ plano'
    ];

    // Verifica√ß√£o mais robusta - qualquer men√ß√£o a PDF deve ser tratada como solicita√ß√£o
    const hasPDFKeyword = pdfKeywords.some(keyword => msg.includes(keyword));
    const hasPDFWord = msg.includes('pdf');
    const hasDownloadIntent = msg.includes('baixar') || msg.includes('download') || msg.includes('exportar');
    const hasGenerateIntent = msg.includes('gerar') || msg.includes('fazer') || msg.includes('criar') || msg.includes('gere') || msg.includes('gera');
    const hasSendIntent = msg.includes('manda') || msg.includes('envia') || msg.includes('enviar');
    const hasPlanoWord = msg.includes('plano');
    
    // Se cont√©m PDF e alguma a√ß√£o de gera√ß√£o/download/envio, √© solicita√ß√£o de PDF
    // Ou se cont√©m "plano" com inten√ß√£o de envio/gera√ß√£o
    const isPDFRequest = hasPDFKeyword || 
                        (hasPDFWord && (hasDownloadIntent || hasGenerateIntent || hasSendIntent)) ||
                        (hasPlanoWord && (hasSendIntent || hasDownloadIntent || hasGenerateIntent));
    
    console.log('üîç [DEBUG] Verifica√ß√£o de PDF:', {
      message: msg,
      hasPDFKeyword,
      hasPDFWord,
      hasDownloadIntent,
      hasGenerateIntent,
      hasSendIntent,
      hasPlanoWord,
      isPDFRequest
    });
    
    return isPDFRequest;
  }

  /**
   * Processa solicita√ß√£o de PDF
   */
  private static async handlePDFRequest(sessionId: string, message: string): Promise<string> {
    try {
      console.log('üìÑ Processando solicita√ß√£o de PDF...');
      
      // Buscar o √∫ltimo plano de aula gerado no hist√≥rico
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const lastPlanoMessage = conversationHistory
        .filter(msg => msg.sender === 'bot' && 
                      (msg.text.includes('Prontinho! Aqui est√° o seu plano de aula') || 
                       msg.text.includes('### Plano de Aula:')))
        .pop();

      if (!lastPlanoMessage) {
        return 'N√£o encontrei um plano de aula recente para gerar o PDF. Voc√™ precisa gerar um plano de aula primeiro! üòä';
      }

      // Extrair o conte√∫do do plano (remover a parte de pr√≥ximos passos)
      const planoContent = this.extractPlanoContent(lastPlanoMessage.text);
      
      if (!planoContent) {
        return 'N√£o consegui extrair o conte√∫do do plano de aula. Tente gerar um novo plano! üòä';
      }

      // Armazenar o conte√∫do do plano para gera√ß√£o via API
      console.log('üíæ Armazenando conte√∫do do plano no contexto...', {
        sessionId: sessionId.substring(0, 8),
        planoContentLength: planoContent.length,
        planoContentPreview: planoContent.substring(0, 100) + '...'
      });
      
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);
      
      // Verificar se foi armazenado corretamente
      const storedContent = ConversationContextManager.getCollectedData(sessionId).lastPlanoContent;
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      console.log('‚úÖ Conte√∫do armazenado:', {
        hasContent: !!storedContent,
        contentLength: storedContent?.length || 0,
        hasPersistentContent: !!persistentContent?.lastPlanoContent,
        persistentContentLength: persistentContent?.lastPlanoContent?.length || 0
      });

      // Buscar dados do plano para gerar sugest√µes personalizadas
      const planoData = ConversationContextManager.getCollectedData(sessionId).lastPlanoData as PlanoAulaData;
      
      // Gerar sugest√µes de continuidade personalizadas
      const continuitySuggestions = planoData ? 
        await this.generateContinuitySuggestions(planoData, sessionId) : 
        `Que legal que voc√™ tem o PDF! üìÑ‚ú® 

Agora que o plano est√° pronto, que tal pensarmos em como dar continuidade a esse tema? 

Posso te ajudar com:
üé® **Projetos interdisciplinares** criativos
üî¨ **Atividades pr√°ticas** que os alunos v√£o adorar
üìö **Leituras complementares** para aprofundar
üéØ **Estrat√©gias de avalia√ß√£o** diferenciadas

O que voc√™ acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? üòä`;

      // Gerar resposta com link de download via API
      const response = `Perfeito! Vou gerar o PDF do seu plano de aula para voc√™! üìÑ‚ú®

<a href="/api/pdf?sessionId=${sessionId}" download="plano-aula.pdf" style="
  display: inline-block;
  background: #007bff;
  color: white;
  padding: 12px 24px;
  text-decoration: none;
  border-radius: 6px;
  font-weight: bold;
  margin: 10px 0;
  cursor: pointer;
">üì• Baixar PDF do Plano de Aula</a>

O arquivo foi gerado com sucesso! Clique no bot√£o acima para fazer o download.

---

${continuitySuggestions}`;

      // Log da a√ß√£o
      ChatLogger.logConversation(sessionId, '[PDF gerado]', 'PDF do plano de aula gerado e disponibilizado para download');

      return response;

    } catch (error) {
      console.error('‚ùå Erro ao processar solicita√ß√£o de PDF:', error);
      ChatLogger.logError(sessionId, error as Error, { context: 'pdf_request' });
      return 'Desculpe, ocorreu um erro ao gerar o PDF. Tente novamente! üòä';
    }
  }

  /**
   * Extrai altera√ß√µes solicitadas para revis√£o do plano
   */
  private static async extractAlteracoesPlano(message: string, sessionId: string): Promise<Partial<PlanoAulaData>> {
    const alteracoes: Partial<PlanoAulaData> = {};
    const msg = message.toLowerCase();

    // Detectar altera√ß√£o de dificuldade
    if (msg.includes('dificuldade') || msg.includes('f√°cil') || msg.includes('m√©dio') || msg.includes('dif√≠cil') || 
        msg.includes('facil') || msg.includes('medio') || msg.includes('dificil')) {
      
      if (msg.includes('f√°cil') || msg.includes('facil')) {
        alteracoes.nivelDificuldade = 'facil';
      } else if (msg.includes('m√©dio') || msg.includes('medio')) {
        alteracoes.nivelDificuldade = 'medio';
      } else if (msg.includes('dif√≠cil') || msg.includes('dificil')) {
        alteracoes.nivelDificuldade = 'dificil';
      }
    }

    // Detectar altera√ß√£o de ano
    const anos = ['1¬∫', '2¬∫', '3¬∫', '4¬∫', '5¬∫', '6¬∫', '7¬∫', '8¬∫', '9¬∫', '1¬∞', '2¬∞', '3¬∞', '4¬∞', '5¬∞', '6¬∞', '7¬∞', '8¬∞', '9¬∞'];
    for (const ano of anos) {
      if (msg.includes(ano)) {
        alteracoes.ano = ano + ' ano';
        break;
      }
    }

    // Detectar altera√ß√£o de tema (usar LLM para extrair tema mais complexo)
    if (msg.includes('tema') || msg.includes('assunto') || msg.includes('conte√∫do') || msg.includes('mat√©ria')) {
      try {
        const { OpenAIService } = await import('./openai');
        const temaExtraido = await OpenAIService.extractTemaFromMessage(message, sessionId);
        if (temaExtraido) {
          alteracoes.tema = temaExtraido;
        }
      } catch (error) {
        ChatLogger.logError(sessionId, error as Error, { context: 'extract_tema', message });
      }
    }

    return alteracoes;
  }

  /**
   * Gera mensagem de continuidade conversacional ap√≥s a gera√ß√£o do plano
   */
  private static async generatePostPlanContinuationMessage(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `Voc√™ √© a ANE, assistente pedag√≥gica. O professor acabou de receber um plano de aula completo.

Dados do plano gerado:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- N√≠vel: ${data.nivelDificuldade || 'm√©dio'}

Gere uma mensagem de continuidade conversacional que:
1. Parabenize o professor pelo plano criado
2. Encoraje a reflex√£o sobre a pr√°tica pedag√≥gica
3. Ofere√ßa suporte para pr√≥ximos passos
4. Seja acolhedora e motivadora
5. Mencione as op√ß√µes de continuidade (ajustes, PDF, novos planos, etc.)

A mensagem deve ser natural, conversacional e incentivar o professor a continuar interagindo.

Exemplo de tom:
"Que plano incr√≠vel criamos juntos! üéâ 
Agora que voc√™ tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 
Posso te ajudar com ajustes, gerar o PDF, ou at√© mesmo criar um novo plano. 
O que voc√™ gostaria de fazer agora?"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Voc√™ √© a ANE, uma assistente pedag√≥gica amig√°vel e encorajadora.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 200,
        temperature: 0.7
      });

      return response.choices[0]?.message?.content || 
        `Que plano incr√≠vel criamos juntos! üéâ 

Agora que voc√™ tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 

Posso te ajudar com:
üëâüèΩ **Ajustes** no plano (dura√ß√£o, atividades, dificuldade)
üëâüèΩ **Gerar PDF** para compartilhar
üëâüèΩ **Criar novo plano** para outro tema
üëâüèΩ **Sugerir atividades** complementares
üëâüèΩ **Tirar d√∫vidas** pedag√≥gicas

O que voc√™ gostaria de fazer agora? üòä`;

    } catch (error) {
      console.error('‚ùå Erro ao gerar mensagem de continuidade:', error);
      return `Que plano incr√≠vel criamos juntos! üéâ 

Agora que voc√™ tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 

Posso te ajudar com:
üëâüèΩ **Ajustes** no plano (dura√ß√£o, atividades, dificuldade)
üëâüèΩ **Gerar PDF** para compartilhar
üëâüèΩ **Criar novo plano** para outro tema
üëâüèΩ **Sugerir atividades** complementares
üëâüèΩ **Tirar d√∫vidas** pedag√≥gicas

O que voc√™ gostaria de fazer agora? üòä`;
    }
  }

  /**
   * Gera sugest√µes de continuidade amig√°veis ap√≥s a gera√ß√£o do PDF
   */
  private static async generateContinuitySuggestions(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `Voc√™ √© a ANE, assistente pedag√≥gica. O professor acabou de gerar o PDF do seu plano de aula.

Dados do plano:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- N√≠vel: ${data.nivelDificuldade || 'm√©dio'}

Gere sugest√µes de continuidade amig√°veis e pr√°ticas que:
1. Sejam espec√≠ficas para o tema e ano do plano
2. Ofere√ßam atividades complementares concretas
3. Sugiram projetos interdisciplinares relevantes
4. Proponham estrat√©gias de aprofundamento
5. Sejam f√°ceis de implementar

Formate como uma conversa natural, n√£o como uma lista formal. Seja encorajadora e mostre entusiasmo pelas possibilidades.

Exemplo de tom:
"Que legal que voc√™ tem o PDF! üìÑ‚ú® 

Agora que o plano est√° pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

üé® **Projeto interdisciplinar**: Que tal conectar com Artes criando... [sugest√£o espec√≠fica]

üî¨ **Atividade pr√°tica**: Uma experi√™ncia simples que os alunos v√£o adorar √©... [sugest√£o espec√≠fica]

üìö **Leitura complementar**: Para aprofundar, sugiro... [sugest√£o espec√≠fica]

O que voc√™ acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa?"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Voc√™ √© a ANE, uma assistente pedag√≥gica criativa e encorajadora que ama sugerir atividades pr√°ticas.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 300,
        temperature: 0.8
      });

      return response.choices[0]?.message?.content || 
        `Que legal que voc√™ tem o PDF! üìÑ‚ú® 

Agora que o plano est√° pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

üé® **Projeto interdisciplinar**: Que tal conectar com outras √°reas do conhecimento?

üî¨ **Atividade pr√°tica**: Uma experi√™ncia simples que os alunos v√£o adorar!

üìö **Leitura complementar**: Para aprofundar o tema de forma divertida!

O que voc√™ acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? üòä`;

    } catch (error) {
      console.error('‚ùå Erro ao gerar sugest√µes de continuidade:', error);
      return `Que legal que voc√™ tem o PDF! üìÑ‚ú® 

Agora que o plano est√° pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

üé® **Projeto interdisciplinar**: Que tal conectar com outras √°reas do conhecimento?

üî¨ **Atividade pr√°tica**: Uma experi√™ncia simples que os alunos v√£o adorar!

üìö **Leitura complementar**: Para aprofundar o tema de forma divertida!

O que voc√™ acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? üòä`;
    }
  }

  /**
   * Gera sugest√µes de temas baseadas no ano escolar
   */
  private static async generateThemeSuggestions(ano: string, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `Voc√™ √© uma assistente pedag√≥gica especializada em sugest√µes de temas para planos de aula.

O professor est√° criando um plano de aula para o ${ano} e pediu sugest√µes de tema.

Gere 5 sugest√µes de temas interessantes e adequados para o ${ano}, considerando:
- A faixa et√°ria dos alunos
- Os interesses t√≠picos dessa idade
- A relev√¢ncia pedag√≥gica
- A possibilidade de atividades pr√°ticas e engajantes

Formate a resposta de forma conversacional e acolhedora, como se fosse a ANE falando.

Exemplo de formato:
"Que legal que voc√™ quer sugest√µes! üí° Aqui est√£o algumas ideias interessantes para o ${ano}:

1. [Tema 1] - [Breve explica√ß√£o do porqu√™ √© interessante]
2. [Tema 2] - [Breve explica√ß√£o do porqu√™ √© interessante]
3. [Tema 3] - [Breve explica√ß√£o do porqu√™ √© interessante]
4. [Tema 4] - [Breve explica√ß√£o do porqu√™ √© interessante]
5. [Tema 5] - [Breve explica√ß√£o do porqu√™ √© interessante]

Qual desses temas te chama mais aten√ß√£o? Ou se preferir, pode me dizer outro tema que voc√™ tem em mente! üòä"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Voc√™ √© a ANE, uma assistente pedag√≥gica amig√°vel e experiente.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 400,
        temperature: 0.7
      });

      return response.choices[0]?.message?.content || 
        `Que legal que voc√™ quer sugest√µes! üí° Aqui est√£o algumas ideias interessantes para o ${ano}:

1. **Fra√ß√µes e decimais** - Um tema super pr√°tico que os alunos usam no dia a dia
2. **Sistema solar** - Sempre fascina as crian√ßas e permite muitas atividades criativas
3. **Ciclo da √°gua** - Tema visual e interativo, perfeito para experimentos
4. **Hist√≥ria do Brasil** - Conte√∫do rico e importante para a forma√ß√£o cidad√£
5. **Animais e habitats** - Tema que desperta curiosidade e permite pesquisas

Qual desses temas te chama mais aten√ß√£o? Ou se preferir, pode me dizer outro tema que voc√™ tem em mente! üòä`;

    } catch (error) {
      console.error('‚ùå Erro ao gerar sugest√µes de tema:', error);
      return `Que legal que voc√™ quer sugest√µes! üí° Aqui est√£o algumas ideias interessantes para o ${ano}:

1. **Fra√ß√µes e decimais** - Um tema super pr√°tico que os alunos usam no dia a dia
2. **Sistema solar** - Sempre fascina as crian√ßas e permite muitas atividades criativas
3. **Ciclo da √°gua** - Tema visual e interativo, perfeito para experimentos
4. **Hist√≥ria do Brasil** - Conte√∫do rico e importante para a forma√ß√£o cidad√£
5. **Animais e habitats** - Tema que desperta curiosidade e permite pesquisas

Qual desses temas te chama mais aten√ß√£o? Ou se preferir, pode me dizer outro tema que voc√™ tem em mente! üòä`;
    }
  }

  /**
   * Extrai o conte√∫do do plano de aula da mensagem
   */
  private static extractPlanoContent(message: string): string | null {
    try {
      // Encontrar onde termina o plano e come√ßam os pr√≥ximos passos
      const nextStepsIndex = message.indexOf('Prontinho! Aqui est√° o seu plano de aula');
      
      if (nextStepsIndex === -1) {
        // Se n√£o encontrar a se√ß√£o de pr√≥ximos passos, retornar toda a mensagem
        return message;
      }

      // Retornar apenas o conte√∫do do plano (antes dos pr√≥ximos passos)
      return message.substring(0, nextStepsIndex).trim();
    } catch (error) {
      console.error('‚ùå Erro ao extrair conte√∫do do plano:', error);
      return null;
    }
  }


  private static async handleContinuarIntent(sessionId: string, message: string): Promise<string> {
    const context = ConversationContextManager.getContext(sessionId);

    // Se j√° temos uma inten√ß√£o ativa, continuar com ela
    if (context.currentIntent && context.currentIntent !== 'saudacao' && context.currentIntent !== 'continuar') {
      return this.generateResponseByIntent(message, sessionId, context.currentIntent);
    }

    // Se n√£o temos inten√ß√£o ativa, analisar hist√≥rico para encontrar sugest√£o anterior
    const recentMessages = ConversationContextManager.getRecentUserMessages(sessionId, 5);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Usar LLM para inferir o que o usu√°rio quer continuar baseado no contexto
    const inferredIntent = await this.inferContinuationIntent(conversationHistory, sessionId);

    if (inferredIntent) {
      ConversationContextManager.updateIntent(sessionId, inferredIntent, 0.9);
      return this.generateResponseByIntent(message, sessionId, inferredIntent);
    }

    // Se n√£o conseguiu identificar contexto, gerar resposta contextual
    return await OpenAIService.generateContextualResponse(
      'continuar_sem_contexto',
      {
        message,
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );
  }

  private static async handleUnclearIntent(message: string, sessionId: string): Promise<string> {
    const msg = message.toLowerCase();
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
    const context = ConversationContextManager.getContext(sessionId);

    // Verificar se h√° um plano anterior e o usu√°rio pode estar se referindo a ele
    const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
    const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;

    // Se o usu√°rio diz que n√£o quer algo ou est√° negando
    if (msg.includes('n√£o quero') || msg.includes('nao quero') ||
        msg.includes('n√£o preciso') || msg.includes('nao preciso')) {
      return await OpenAIService.generateContextualResponse(
        'negacao',
        {
          message,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );
    }

    // Verificar se parece uma pergunta (tira-d√∫vidas)
    if (msg.includes('?') || msg.includes('como') || msg.includes('que') ||
        msg.includes('qual') || msg.includes('quando') || msg.includes('onde') ||
        msg.includes('por que') || msg.includes('porque')) {

      // Processar como tira-d√∫vidas
      return await OpenAIService.generateResponse(message, sessionId);
    }

    // Se h√° um plano anterior e a mensagem √© vaga, oferecer op√ß√µes contextuais
    if (hasPreviousPlan && (msg.length < 20 || msg.includes('e agora') || msg.includes('o que') || msg.includes('como'))) {
      return `Entendi! Vejo que voc√™ tem um plano anterior. O que voc√™ gostaria de fazer agora?

üëâüèΩ **Gerar PDF** do plano (digite "manda o plano" ou "gerar pdf")
üëâüèΩ **Criar novo plano** de aula
üëâüèΩ **Ajustar o plano** anterior (alterar dificuldade, ano ou tema)
üëâüèΩ **Sugerir atividades** complementares
üëâüèΩ **Tirar d√∫vidas** pedag√≥gicas

Qual op√ß√£o te interessa? üòä`;
    }

    // Fallback geral - inten√ß√£o n√£o clara
    return await OpenAIService.generateContextualResponse(
      'unclear_intent',
      {
        message,
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );
  }
}