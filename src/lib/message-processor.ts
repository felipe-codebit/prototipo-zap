import { simpleNlpService } from './simple-nlp';
import { OpenAIService } from './openai';
import { ConversationContextManager } from './conversation-context';
import { ChatLogger } from './logger';
import { Intent, PlanoAulaData, PlanejamentoSemanalData } from '@/types';

export class MessageProcessor {
  static async processMessage(message: string, sessionId: string): Promise<string> {
    try {
      const msg = message.toLowerCase().trim();
      
      // VerificaÃ§Ã£o prioritÃ¡ria para comando "sair" - deve funcionar em qualquer momento
      if (['sair', 'cancelar', 'parar', 'reiniciar', 'recomeÃ§ar', 'volta', 'voltar'].includes(msg) ||
          msg.includes('comeÃ§ar de novo') || msg.includes('comeÃ§ar denovo') ||
          msg.includes('sair daqui') || msg.includes('cancelar tudo')) {
        return this.handleSairIntent(sessionId);
      }

      // VerificaÃ§Ã£o prioritÃ¡ria para geraÃ§Ã£o de PDF - DEVE vir antes da anÃ¡lise de intenÃ§Ã£o
      if (this.isPDFRequest(msg)) {
        console.log('ğŸ“„ SolicitaÃ§Ã£o de PDF detectada:', message);
        console.log('ğŸ“„ Interrompendo processamento normal para gerar PDF');
        return this.handlePDFRequest(sessionId, message);
      }

      const currentContext = ConversationContextManager.getContext(sessionId);
      console.log('ğŸš€ [DEBUG] processMessage iniciado:', {
        message: message.substring(0, 50),
        sessionId: sessionId.substring(0, 8),
        currentIntent: currentContext.currentIntent,
        hasCollectedData: Object.keys(currentContext.collectedData).length > 0
      });



      const currentIntent = currentContext.currentIntent;

      // Analisar intenÃ§Ã£o
      const intentAnalysis = await simpleNlpService.analyzeIntent(message, sessionId);

      // Decidir qual intenÃ§Ã£o usar: manter atual se estivermos coletando dados ou usar nova se clara
      let finalIntent = intentAnalysis.intent;
      let finalConfidence = intentAnalysis.confidence;

      // Se jÃ¡ temos uma intenÃ§Ã£o ativa e estamos coletando dados, manter a intenÃ§Ã£o atual
      // a menos que a nova intenÃ§Ã£o seja muito clara (confianÃ§a > 0.8)
      if (currentIntent &&
          currentIntent !== 'saudacao' &&
          currentIntent !== 'despedida' &&
          currentIntent !== 'unclear' &&
          Object.keys(currentContext.collectedData).length > 0) {

        // Se a nova intenÃ§Ã£o nÃ£o Ã© muito clara, manter a atual
        if (intentAnalysis.confidence < 0.8 || intentAnalysis.intent === 'unclear') {
          finalIntent = currentIntent;
          finalConfidence = currentContext.intentConfidence;

          ChatLogger.logIntent(sessionId, `${finalIntent} (mantida)`, finalConfidence, message);
        }
      }

      // Atualizar contexto
      ConversationContextManager.updateIntent(sessionId, finalIntent, finalConfidence);



      // Gerar resposta baseada na intenÃ§Ã£o
      return await this.generateResponseByIntent(message, sessionId, finalIntent);

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { message });
      return 'Desculpe, ocorreu um erro ao processar sua mensagem. Pode tentar novamente?';
    }
  }





  private static async extractAdditionalInfo(sessionId: string, intent: Intent) {
    const recentMessages = ConversationContextManager.getRecentUserMessages(sessionId, 3);
    const latestMessage = recentMessages[recentMessages.length - 1];
    const currentContext = ConversationContextManager.getContext(sessionId);

    if (!latestMessage) return;

    // Usar a intenÃ§Ã£o atual se estivermos coletando informaÃ§Ãµes do usuÃ¡rio
    const effectiveIntent = (currentContext.currentIntent &&
                           Object.keys(currentContext.collectedData).length > 0)
                           ? currentContext.currentIntent
                           : intent;

    // Usar LLM para extrair dados de forma inteligente
    if (effectiveIntent === 'plano_aula' || effectiveIntent === 'planejamento_semanal') {
      const extractedData = await OpenAIService.extractDataFromMessage(
        latestMessage,
        effectiveIntent,
        currentContext.collectedData,
        sessionId
      );

      // Atualizar dados coletados com o que foi extraÃ­do
      for (const [key, value] of Object.entries(extractedData)) {
        if (value) {
          ConversationContextManager.updateCollectedData(sessionId, key, value);
        }
      }
    }
  }

  // FunÃ§Ãµes antigas de extraÃ§Ã£o baseadas em keywords foram removidas
  // Agora usamos extractDataFromMessage da OpenAIService que usa LLM

  /**
   * Infere o que o usuÃ¡rio quer continuar com base no histÃ³rico da conversa
   */
  private static async inferContinuationIntent(
    conversationHistory: Array<{ sender: string; text: string }>,
    sessionId: string
  ): Promise<Intent | null> {
    try {
      const recentHistory = conversationHistory.slice(-6).map(msg =>
        `${msg.sender === 'user' ? 'Professor' : 'Ane'}: ${msg.text}`
      ).join('\n');

      const prompt = `Analise o histÃ³rico da conversa e identifique o que o professor quer continuar fazendo.

HISTÃ“RICO:
${recentHistory}

O professor disse que quer "continuar". Com base no contexto, o que ele provavelmente quer fazer?

OPÃ‡Ã•ES:
- plano_aula: Quer criar/continuar criando um plano de aula
- planejamento_semanal: Quer criar/continuar um planejamento semanal
- tira_duvidas: Quer fazer perguntas/tirar dÃºvidas
- null: NÃ£o hÃ¡ contexto claro do que continuar

Analise:
- O que a Ane sugeriu nas Ãºltimas mensagens?
- Qual era o tÃ³pico da conversa?
- Houve algum plano/tarefa mencionado?

Retorne APENAS JSON: {"intent": "nome_ou_null", "confidence": 0.0}`;

      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'VocÃª Ã© um analisador de contexto conversacional.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 100,
        temperature: 0.1
      });

      const result = response.choices[0]?.message?.content?.trim();
      if (!result) return null;

      const parsed = JSON.parse(result);
      if (parsed.confidence >= 0.7 && parsed.intent !== 'null') {
        return parsed.intent as Intent;
      }

      return null;
    } catch (error) {
      console.error('Erro ao inferir intenÃ§Ã£o de continuaÃ§Ã£o:', error);
      return null;
    }
  }

  private static async generateResponseByIntent(message: string, sessionId: string, intent: Intent): Promise<string> {
    switch (intent) {
      case 'plano_aula':
        return this.handlePlanoAulaIntent(sessionId);

      case 'planejamento_semanal':
        return this.handlePlanejamentoSemanalIntent(sessionId);

      case 'tira_duvidas':
        return OpenAIService.generateResponse(message, sessionId);

      case 'saudacao':
        return await this.handleSaudacao(message, sessionId);

      case 'despedida':
        return this.handleDespedida(sessionId);

      case 'sair':
        return this.handleSairIntent(sessionId);

      case 'continuar':
        return this.handleContinuarIntent(sessionId, message);

      case 'revisar_plano':
        return this.handleRevisarPlanoIntent(sessionId, message);

      case 'reflexao_pedagogica':
        return this.handleReflexaoPedagogicaIntent(sessionId, message);

      default:
        return this.handleUnclearIntent(message, sessionId);
    }
  }

  private static async handleRevisarPlanoIntent(sessionId: string, message: string): Promise<string> {
    try {
      // Verificar se hÃ¡ um plano anterior para revisar
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      
      if (!persistentContent?.lastPlanoContent) {
        return "NÃ£o encontrei um plano de aula anterior para revisar. VocÃª precisa primeiro gerar um plano de aula antes de poder revisÃ¡-lo. Gostaria de criar um novo plano?";
      }

      // Extrair informaÃ§Ãµes de alteraÃ§Ã£o da mensagem
      const alteracoes = await this.extractAlteracoesPlano(message, sessionId);
      
      if (Object.keys(alteracoes).length === 0) {
        return "Entendi que vocÃª quer revisar o plano, mas nÃ£o consegui identificar o que deseja alterar. VocÃª pode especificar se quer mudar:\n\nâ€¢ A dificuldade (fÃ¡cil, mÃ©dio, difÃ­cil)\nâ€¢ O ano escolar\nâ€¢ O tema/habilidade BNCC\n\nPor exemplo: 'alterar a dificuldade para fÃ¡cil' ou 'mudar para 5Âº ano'";
      }

      // Obter dados do plano original
      const dadosOriginais = ConversationContextManager.getCollectedData(sessionId) as PlanoAulaData;
      
      // Aplicar alteraÃ§Ãµes
      const novosDados = { ...dadosOriginais, ...alteracoes };
      
      // Atualizar dados coletados
      Object.keys(alteracoes).forEach(key => {
        ConversationContextManager.updateCollectedData(sessionId, key, alteracoes[key]);
      });

      // Gerar novo plano com as alteraÃ§Ãµes
      const novoPlano = await OpenAIService.generatePlanoAula(novosDados, sessionId);
      
      // Preservar o novo conteÃºdo
      const planoContent = this.extractPlanoContent(novoPlano);
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);

      // Gerar resposta contextual
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'plano_revisado',
        {
          collectedData: { ...novosDados, alteracoes: alteracoes },
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // Resetar contexto mantendo histÃ³rico e dados do plano
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanoContent']);

      return `${contextualResponse}\n\n${novoPlano}\n\nâœ… Plano revisado com sucesso! As alteraÃ§Ãµes foram aplicadas.`;

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { context: 'revisar_plano', message });
      return "Desculpe, ocorreu um erro ao revisar o plano. Tente novamente ou digite 'sair' para reiniciar.";
    }
  }

  private static async handleReflexaoPedagogicaIntent(sessionId: string, message: string): Promise<string> {
    try {
      // Verificar se hÃ¡ um plano anterior para referÃªncia
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;
      
      if (!hasPreviousPlan) {
        return "Que legal que vocÃª quer refletir sobre a prÃ¡tica pedagÃ³gica! ğŸ’­\n\nPara te ajudar melhor, seria interessante ter um plano de aula como referÃªncia. VocÃª gostaria de criar um plano primeiro ou prefere conversar sobre algum aspecto especÃ­fico da sua prÃ¡tica?";
      }

      // Gerar prompt de reflexÃ£o pedagÃ³gica amigÃ¡vel
      const planoData = ConversationContextManager.getCollectedData(sessionId).lastPlanoData as PlanoAulaData;
      const reflectionPrompt = await this.generateReflectionPrompt(planoData, sessionId);

      return reflectionPrompt;

    } catch (error) {
      ChatLogger.logError(sessionId, error as Error, { context: 'reflexao_pedagogica', message });
      return "Desculpe, ocorreu um erro ao processar sua reflexÃ£o. Tente novamente ou digite 'sair' para reiniciar.";
    }
  }

  /**
   * Gera um prompt amigÃ¡vel para reflexÃ£o pedagÃ³gica baseado em exemplos passados
   */
  private static async generateReflectionPrompt(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `VocÃª Ã© a ANE, assistente pedagÃ³gica. O professor quer refletir sobre sua prÃ¡tica pedagÃ³gica.

Dados do plano de referÃªncia:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- NÃ­vel: ${data.nivelDificuldade || 'mÃ©dio'}

Crie um prompt de reflexÃ£o pedagÃ³gica que:
1. Seja acolhedor e encorajador
2. Instigue o professor a pensar profundamente sobre sua prÃ¡tica
3. Use exemplos especÃ­ficos do plano como base
4. FaÃ§a perguntas que extraiam feedback valioso
5. Seja conversacional e natural
6. OfereÃ§a diferentes Ã¢ngulos de reflexÃ£o

O prompt deve ser como uma conversa entre colegas, nÃ£o um questionÃ¡rio formal. Use o tema e ano do plano para personalizar as perguntas.

Exemplo de tom:
"Que bom que vocÃª quer refletir sobre sua prÃ¡tica! ğŸ’­ 

Vejo que vocÃª trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experiÃªncia? Me conta:

ğŸ¯ **O que mais te surpreendeu** durante a implementaÃ§Ã£o desse plano? Houve algum momento em que vocÃª pensou 'nossa, nÃ£o esperava que fosse assim'?

ğŸ‘¥ **Como foi a reaÃ§Ã£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que vocÃª esperava? O que isso te ensinou?

ğŸ’¡ **Que insights vocÃª teve** sobre como seus alunos aprendem melhor? Descobriu alguma estratÃ©gia que funcionou especialmente bem?

ğŸ”„ **Se fosse fazer de novo**, o que vocÃª mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experiÃªncia! Conte-me o que mais te marcou nessa aula. ğŸ˜Š"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'VocÃª Ã© a ANE, uma assistente pedagÃ³gica que ama ouvir e aprender com as experiÃªncias dos professores.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 400,
        temperature: 0.8
      });

      return response.choices[0]?.message?.content || 
        `Que bom que vocÃª quer refletir sobre sua prÃ¡tica! ğŸ’­ 

Vejo que vocÃª trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experiÃªncia? Me conta:

ğŸ¯ **O que mais te surpreendeu** durante a implementaÃ§Ã£o desse plano? Houve algum momento em que vocÃª pensou 'nossa, nÃ£o esperava que fosse assim'?

ğŸ‘¥ **Como foi a reaÃ§Ã£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que vocÃª esperava? O que isso te ensinou?

ğŸ’¡ **Que insights vocÃª teve** sobre como seus alunos aprendem melhor? Descobriu alguma estratÃ©gia que funcionou especialmente bem?

ğŸ”„ **Se fosse fazer de novo**, o que vocÃª mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experiÃªncia! Conte-me o que mais te marcou nessa aula. ğŸ˜Š`;

    } catch (error) {
      console.error('âŒ Erro ao gerar prompt de reflexÃ£o:', error);
      return `Que bom que vocÃª quer refletir sobre sua prÃ¡tica! ğŸ’­ 

Vejo que vocÃª trabalhou com ${data.tema || data.habilidadeBNCC} no ${data.ano} - que tema interessante! 

Vamos pensar juntos sobre essa experiÃªncia? Me conta:

ğŸ¯ **O que mais te surpreendeu** durante a implementaÃ§Ã£o desse plano? Houve algum momento em que vocÃª pensou 'nossa, nÃ£o esperava que fosse assim'?

ğŸ‘¥ **Como foi a reaÃ§Ã£o dos alunos**? Teve algum aluno que reagiu de forma diferente do que vocÃª esperava? O que isso te ensinou?

ğŸ’¡ **Que insights vocÃª teve** sobre como seus alunos aprendem melhor? Descobriu alguma estratÃ©gia que funcionou especialmente bem?

ğŸ”„ **Se fosse fazer de novo**, o que vocÃª mudaria? Que ajustes faria baseado no que observou?

Estou aqui para ouvir e aprender com sua experiÃªncia! Conte-me o que mais te marcou nessa aula. ğŸ˜Š`;
    }
  }

  private static async handlePlanoAulaIntent(sessionId: string): Promise<string> {
    // Extrair informaÃ§Ãµes da mensagem atual no contexto da intenÃ§Ã£o
    await this.extractAdditionalInfo(sessionId, 'plano_aula');

    const missingData = ConversationContextManager.getMissingDataForPlanoAula(sessionId);

    if (missingData.length === 0) {
      // Todos os dados coletados, gerar plano de aula
      const data = ConversationContextManager.getCollectedData(sessionId) as PlanoAulaData;
      const planoAula = await OpenAIService.generatePlanoAula(data, sessionId);

      // Gerar resposta contextual e conversacional
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'plano_aula_completo',
        {
          collectedData: data,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // Adicionar mensagem de continuidade conversacional
      const continuationMessage = await this.generatePostPlanContinuationMessage(data, sessionId);

      // IMPORTANTE: Preservar o conteÃºdo do plano para geraÃ§Ã£o de PDF posterior
      const planoContent = this.extractPlanoContent(planoAula);
      if (planoContent) {
        ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);
        // TambÃ©m preservar os dados do plano para referÃªncia futura
        ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoData', data);
      }

      // Limpar contexto mas preservar o conteÃºdo do plano e dados
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanoContent', 'lastPlanoData']);

      return `${contextualResponse}\n\n${planoAula}\n\n${continuationMessage}`;
    } else {
      // Ainda faltam dados, perguntar especificamente
      return await this.askForMissingPlanoAulaData(missingData, sessionId);
    }
  }

  private static async handlePlanejamentoSemanalIntent(sessionId: string): Promise<string> {
    // Extrair informaÃ§Ãµes da mensagem atual no contexto da intenÃ§Ã£o
    await this.extractAdditionalInfo(sessionId, 'planejamento_semanal');

    const missingData = ConversationContextManager.getMissingDataForPlanejamentoSemanal(sessionId);

    if (missingData.length === 0) {
      // Todos os dados coletados, gerar planejamento semanal
      const data = ConversationContextManager.getCollectedData(sessionId) as PlanejamentoSemanalData;
      const planejamento = await OpenAIService.generatePlanejamentoSemanal(data, sessionId);

      // Gerar resposta contextual e conversacional
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const contextualResponse = await OpenAIService.generateContextualResponse(
        'planejamento_semanal_completo',
        {
          collectedData: data,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );

      // IMPORTANTE: Preservar o conteÃºdo do planejamento para geraÃ§Ã£o de PDF posterior
      const planejamentoContent = planejamento; // Para planejamento semanal, usar o conteÃºdo completo
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanejamentoContent', planejamentoContent);
      // TambÃ©m preservar os dados do planejamento para referÃªncia futura
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanejamentoData', data);

      // Limpar contexto mas preservar o conteÃºdo do planejamento e dados
      ConversationContextManager.resetContextKeepingHistoryAndData(sessionId, ['lastPlanejamentoContent', 'lastPlanejamentoData']);

      return `${contextualResponse}\n\n${planejamento}`;
    } else {
      // Ainda faltam dados
      return await this.askForMissingPlanejamentoSemanalData(missingData, sessionId);
    }
  }

  private static async askForMissingPlanoAulaData(missingData: string[], sessionId: string): Promise<string> {
    const collectedData = ConversationContextManager.getCollectedData(sessionId);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Verificar se o usuÃ¡rio estÃ¡ pedindo sugestÃµes de tema
    const lastUserMessage = conversationHistory
      .filter(msg => msg.sender === 'user')
      .pop()?.text.toLowerCase() || '';

    const isAskingForSuggestions = lastUserMessage.includes('sugira') || 
                                  lastUserMessage.includes('sugestÃ£o') || 
                                  lastUserMessage.includes('sugestÃµes') ||
                                  lastUserMessage.includes('tanto faz') ||
                                  lastUserMessage.includes('qualquer') ||
                                  lastUserMessage.includes('nÃ£o sei') ||
                                  lastUserMessage.includes('nao sei') ||
                                  lastUserMessage.includes('me ajuda') ||
                                  lastUserMessage.includes('me ajuda a escolher');

    if (isAskingForSuggestions && missingData.includes('tema ou habilidade BNCC')) {
      // Gerar sugestÃµes de temas baseadas no ano escolar
      const ano = collectedData.ano || '5Âº ano'; // Default para 5Âº ano se nÃ£o especificado
      return await this.generateThemeSuggestions(ano, sessionId);
    }

    // Gera a pergunta conversacional usando a LLM para todos os dados faltantes
    const question = await OpenAIService.generateConversationalQuestion(
      missingData.join(', '), // Passa todos os campos faltantes
      collectedData,
      conversationHistory.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text
      })),
      sessionId
    );

    return question;
  }

  private static async askForMissingPlanejamentoSemanalData(missingData: string[], sessionId: string): Promise<string> {
    const collectedData = ConversationContextManager.getCollectedData(sessionId);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Gera a pergunta conversacional usando a LLM para todos os dados faltantes
    const question = await OpenAIService.generateConversationalQuestion(
      missingData.join(', '), // Passa todos os campos faltantes
      collectedData,
      conversationHistory.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text
      })),
      sessionId
    );

    return question;
  }

  private static async handleSaudacao(message: string, sessionId: string): Promise<string> {
    console.log('ğŸ‘‹ [DEBUG] Processando saudaÃ§Ã£o com LLM');

    try {
      const { OpenAIService } = await import('./openai');
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      // Verificar se hÃ¡ um plano anterior para referÃªncia contextual
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;
      
      let contextInfo = '';
      if (hasPreviousPlan) {
        contextInfo = `
CONTEXTO IMPORTANTE: O professor jÃ¡ tem um plano anterior gerado nesta conversa. 
Se ele fizer uma saudaÃ§Ã£o simples, mencione que pode continuar trabalhando com o plano anterior ou criar um novo.
Se ele perguntar sobre funcionalidades, inclua opÃ§Ãµes como "gerar PDF do plano anterior" ou "ajustar o plano".
`;
      }

      const promptParaSaudacao = `
A mensagem do professor: "${message}"

${contextInfo}

â¡ï¸ Regras de comportamento:

1. SEMPRE reconheÃ§a saudaÃ§Ãµes e "small talk" (ex.: "oi, tudo bem?", "bom dia!", "tudo certo?", "como vocÃª pode ajudar?") antes de qualquer instruÃ§Ã£o, de forma natural e acolhedora.

2. Sua apresentaÃ§Ã£o deve sempre usar como base a mensagem abaixo, adaptando a linguagem para soar natural e prÃ³xima do professor:
"Oi, eu sou a ANE, sua assistente pedagÃ³gica. ğŸ‘©ğŸ½â€ğŸ«ğŸ’¡  
Quero te mostrar rapidinho como posso te ajudar por aqui, tudo bem?"

3. SEMPRE explique o que vocÃª consegue fazer, mesmo quando houver uma solicitaÃ§Ã£o especÃ­fica.
Liste claramente suas principais funÃ§Ãµes:
ğŸ‘‰ğŸ½ Crio planos de aula
ğŸ‘‰ğŸ½ Trago ideias de metodologias e atividades
ğŸ‘‰ğŸ½ Ajudo na reflexÃ£o sobre suas prÃ¡ticas pedagÃ³gicas
ğŸ’¬ Para te ajudar preciso saber o ano e tema ou habilidade da sua aula

4. Se o professor jÃ¡ trouxer uma solicitaÃ§Ã£o, adapte a explicaÃ§Ã£o acima ao contexto e incentive que ele dÃª mais detalhes.

5. SEMPRE finalize mostrando que Ã© um prazer ajudar.

${hasPreviousPlan ? `
6. IMPORTANTE: Se hÃ¡ um plano anterior, mencione as opÃ§Ãµes de continuar com ele:
- Gerar PDF do plano anterior
- Ajustar o plano anterior
- Criar um novo plano
` : ''}

EXEMPLOS DE RESPOSTAS:

Se o professor mandar apenas "Oi, tudo bem?":
"Oi, tudo bem? Eu sou a ANE, sua assistente pedagÃ³gica ğŸ‘©ğŸ½â€ğŸ«ğŸ’¡.
Quero te mostrar rapidinho como posso te ajudar por aqui.
ğŸ‘‰ğŸ½ Crio planos de aula
ğŸ‘‰ğŸ½ Trago ideias de metodologias e atividades
ğŸ‘‰ğŸ½ Ajudo na reflexÃ£o sobre suas prÃ¡ticas pedagÃ³gicas
ğŸ’¬ Para comeÃ§ar, me conta o ano e o tema ou habilidade que vocÃª quer trabalhar?
Vai ser um prazer te ajudar!"

Se o professor mandar "Como vocÃª pode ajudar?" ou "O que vocÃª faz?":
"Oi! Eu sou a ANE, sua assistente pedagÃ³gica ğŸ‘©ğŸ½â€ğŸ«ğŸ’¡.
Que bom vocÃª perguntar! Vou te mostrar rapidinho como posso te ajudar por aqui.
ğŸ‘‰ğŸ½ Crio planos de aula
ğŸ‘‰ğŸ½ Trago ideias de metodologias e atividades
ğŸ‘‰ğŸ½ Ajudo na reflexÃ£o sobre suas prÃ¡ticas pedagÃ³gicas
ğŸ’¬ Para comeÃ§ar, me conta o ano e o tema ou habilidade que vocÃª quer trabalhar?
Vai ser um prazer te ajudar!"

Se o professor mandar "Oi, bom dia, me ajuda a planejar uma aula sobre fraÃ§Ãµes para o 6Âº ano?":
"Oi, bom dia! Eu sou a ANE, sua assistente pedagÃ³gica ğŸ‘©ğŸ½â€ğŸ«ğŸ’¡.
Que Ã³timo vocÃª jÃ¡ trazer seu pedido! Antes de comeÃ§armos, deixa eu te contar rapidinho como posso te ajudar:
ğŸ‘‰ğŸ½ Crio planos de aula
ğŸ‘‰ğŸ½ Trago ideias de metodologias e atividades
ğŸ‘‰ğŸ½ Ajudo na reflexÃ£o sobre suas prÃ¡ticas pedagÃ³gicas
ğŸ’¬ VocÃª mencionou fraÃ§Ãµes para o 6Âº ano. Quer que eu crie um plano completo com atividades ou prefere sÃ³ ideias de metodologias para essa habilidade?"
`;

      const response = await client.chat.completions.create({
        model: 'gpt-4-turbo',
        messages: [
          { role: 'system', content: promptParaSaudacao },
          { role: 'user', content: message }
        ],
        max_tokens: 300,
        temperature: 0.7
      });

      const botResponse = response.choices[0]?.message?.content ||
        `Oi! Eu sou a ANE, sua assistente pedagÃ³gica. Como posso te ajudar?`;

      console.log('âœ… [DEBUG] Resposta LLM para saudaÃ§Ã£o gerada');
      
      // Adicionar marcador para vÃ­deo de saudaÃ§Ã£o
      return `[VIDEO_SAUDACAO]${botResponse}`;

    } catch (error) {
      console.error('âŒ [DEBUG] Erro no LLM para saudaÃ§Ã£o:', error);
      // Fallback em caso de erro
      return `[VIDEO_SAUDACAO]Oi! Eu sou a ANE, sua assistente pedagÃ³gica. ğŸ‘©ğŸ½â€ğŸ«ğŸ’¡ Como posso te ajudar hoje?`;
    }
  }

  private static async handleDespedida(sessionId: string): Promise<string> {
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    const response = await OpenAIService.generateContextualResponse(
      'despedida',
      {
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );

    ConversationContextManager.clearContext(sessionId);
    return response;
  }

  private static async handleSairIntent(sessionId: string): Promise<string> {
    // Registrar a mensagem do usuÃ¡rio no histÃ³rico antes de resetar o contexto
    ConversationContextManager.addMessage(sessionId, {
      id: `user_${Date.now()}`,
      text: '[UsuÃ¡rio solicitou reiniciar conversa]',
      sender: 'user',
      timestamp: new Date(),
      type: 'text'
    });

    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    const response = await OpenAIService.generateContextualResponse(
      'reiniciar',
      {
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );

    ConversationContextManager.resetContextKeepingHistory(sessionId);

    // Registrar a resposta do bot no histÃ³rico
    ConversationContextManager.addMessage(sessionId, {
      id: `bot_${Date.now()}`,
      text: response,
      sender: 'bot',
      timestamp: new Date(),
      type: 'text'
    });

    return response;
  }

  /**
   * Verifica se a mensagem Ã© uma solicitaÃ§Ã£o de PDF
   */
  private static isPDFRequest(message: string): boolean {
    const msg = message.toLowerCase().trim();
    
    const pdfKeywords = [
      'gerar pdf',
      'gerar em pdf',
      'fazer pdf',
      'criar pdf',
      'baixar pdf',
      'exportar pdf',
      'pdf do plano',
      'plano em pdf',
      'baixar plano',
      'exportar plano',
      'compartilhar pdf',
      'enviar pdf',
      'quero pdf',
      'preciso pdf',
      'fazer download',
      'baixar arquivo',
      'exportar arquivo',
      'quero gerar o pdf',
      'quero gerar pdf',
      'gerar o pdf',
      'fazer o pdf',
      'criar o pdf',
      'baixar o pdf',
      'gere o pdf',
      'gera o pdf',
      'gere pdf',
      'gera pdf',
      'gera o pdf',
      'faz o pdf',
      'cria o pdf',
      'baixa o pdf',
      'exporta o pdf',
      'compartilha o pdf',
      'envia o pdf',
      'quero o pdf',
      'preciso o pdf',
      'faz o pdf',
      'cria o pdf',
      'baixa o pdf',
      'exporta o pdf',
      'compartilha o pdf',
      'envia o pdf',
      'quero o pdf',
      'preciso o pdf',
      'faz o pdf',
      'quero em pdf',
      // Termos coloquiais para solicitaÃ§Ã£o de PDF
      'manda o plano',
      'manda o pdf',
      'manda pdf',
      'manda plano',
      'envia o plano',
      'envia plano',
      'me manda o plano',
      'me manda o pdf',
      'me manda pdf',
      'me manda plano',
      'me envia o plano',
      'me envia o pdf',
      'me envia pdf',
      'me envia plano',
      'pode mandar o plano',
      'pode mandar o pdf',
      'pode mandar pdf',
      'pode mandar plano',
      'pode enviar o plano',
      'pode enviar o pdf',
      'pode enviar pdf',
      'pode enviar plano',
      'manda aÃ­ o plano',
      'manda aÃ­ o pdf',
      'manda aÃ­ pdf',
      'manda aÃ­ plano',
      'envia aÃ­ o plano',
      'envia aÃ­ o pdf',
      'envia aÃ­ pdf',
      'envia aÃ­ plano'
    ];

    // VerificaÃ§Ã£o mais robusta - qualquer menÃ§Ã£o a PDF deve ser tratada como solicitaÃ§Ã£o
    const hasPDFKeyword = pdfKeywords.some(keyword => msg.includes(keyword));
    const hasPDFWord = msg.includes('pdf');
    const hasDownloadIntent = msg.includes('baixar') || msg.includes('download') || msg.includes('exportar');
    const hasGenerateIntent = msg.includes('gerar') || msg.includes('fazer') || msg.includes('criar') || msg.includes('gere') || msg.includes('gera');
    const hasSendIntent = msg.includes('manda') || msg.includes('envia') || msg.includes('enviar');
    const hasPlanoWord = msg.includes('plano');
    
    // Se contÃ©m PDF e alguma aÃ§Ã£o de geraÃ§Ã£o/download/envio, Ã© solicitaÃ§Ã£o de PDF
    // Ou se contÃ©m "plano" com intenÃ§Ã£o de envio/geraÃ§Ã£o
    const isPDFRequest = hasPDFKeyword || 
                        (hasPDFWord && (hasDownloadIntent || hasGenerateIntent || hasSendIntent)) ||
                        (hasPlanoWord && (hasSendIntent || hasDownloadIntent || hasGenerateIntent));
    
    console.log('ğŸ” [DEBUG] VerificaÃ§Ã£o de PDF:', {
      message: msg,
      hasPDFKeyword,
      hasPDFWord,
      hasDownloadIntent,
      hasGenerateIntent,
      hasSendIntent,
      hasPlanoWord,
      isPDFRequest
    });
    
    return isPDFRequest;
  }

  /**
   * Processa solicitaÃ§Ã£o de PDF
   */
  private static async handlePDFRequest(sessionId: string, message: string): Promise<string> {
    try {
      console.log('ğŸ“„ Processando solicitaÃ§Ã£o de PDF...');
      
      // Buscar o Ãºltimo plano de aula gerado no histÃ³rico
      const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
      const lastPlanoMessage = conversationHistory
        .filter(msg => msg.sender === 'bot' && 
                      (msg.text.includes('Prontinho! Aqui estÃ¡ o seu plano de aula') || 
                       msg.text.includes('### Plano de Aula:')))
        .pop();

      if (!lastPlanoMessage) {
        return 'NÃ£o encontrei um plano de aula recente para gerar o PDF. VocÃª precisa gerar um plano de aula primeiro! ğŸ˜Š';
      }

      // Extrair o conteÃºdo do plano (remover a parte de prÃ³ximos passos)
      const planoContent = this.extractPlanoContent(lastPlanoMessage.text);
      
      if (!planoContent) {
        return 'NÃ£o consegui extrair o conteÃºdo do plano de aula. Tente gerar um novo plano! ğŸ˜Š';
      }

      // Armazenar o conteÃºdo do plano para geraÃ§Ã£o via API
      console.log('ğŸ’¾ Armazenando conteÃºdo do plano no contexto...', {
        sessionId: sessionId.substring(0, 8),
        planoContentLength: planoContent.length,
        planoContentPreview: planoContent.substring(0, 100) + '...'
      });
      
      ConversationContextManager.updateCollectedData(sessionId, 'lastPlanoContent', planoContent);
      
      // Verificar se foi armazenado corretamente
      const storedContent = ConversationContextManager.getCollectedData(sessionId).lastPlanoContent;
      const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
      console.log('âœ… ConteÃºdo armazenado:', {
        hasContent: !!storedContent,
        contentLength: storedContent?.length || 0,
        hasPersistentContent: !!persistentContent?.lastPlanoContent,
        persistentContentLength: persistentContent?.lastPlanoContent?.length || 0
      });

      // Buscar dados do plano para gerar sugestÃµes personalizadas
      const planoData = ConversationContextManager.getCollectedData(sessionId).lastPlanoData as PlanoAulaData;
      
      // Gerar sugestÃµes de continuidade personalizadas
      const continuitySuggestions = planoData ? 
        await this.generateContinuitySuggestions(planoData, sessionId) : 
        `Que legal que vocÃª tem o PDF! ğŸ“„âœ¨ 

Agora que o plano estÃ¡ pronto, que tal pensarmos em como dar continuidade a esse tema? 

Posso te ajudar com:
ğŸ¨ **Projetos interdisciplinares** criativos
ğŸ”¬ **Atividades prÃ¡ticas** que os alunos vÃ£o adorar
ğŸ“š **Leituras complementares** para aprofundar
ğŸ¯ **EstratÃ©gias de avaliaÃ§Ã£o** diferenciadas

O que vocÃª acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? ğŸ˜Š`;

      // Gerar resposta com link de download via API
      const response = `Perfeito! Vou gerar o PDF do seu plano de aula para vocÃª! ğŸ“„âœ¨

<a href="/api/pdf?sessionId=${sessionId}" download="plano-aula.pdf" style="
  display: inline-block;
  background: #007bff;
  color: white;
  padding: 12px 24px;
  text-decoration: none;
  border-radius: 6px;
  font-weight: bold;
  margin: 10px 0;
  cursor: pointer;
">ğŸ“¥ Baixar PDF do Plano de Aula</a>

O arquivo foi gerado com sucesso! Clique no botÃ£o acima para fazer o download.

---

${continuitySuggestions}`;

      // Log da aÃ§Ã£o
      ChatLogger.logConversation(sessionId, '[PDF gerado]', 'PDF do plano de aula gerado e disponibilizado para download');

      return response;

    } catch (error) {
      console.error('âŒ Erro ao processar solicitaÃ§Ã£o de PDF:', error);
      ChatLogger.logError(sessionId, error as Error, { context: 'pdf_request' });
      return 'Desculpe, ocorreu um erro ao gerar o PDF. Tente novamente! ğŸ˜Š';
    }
  }

  /**
   * Extrai alteraÃ§Ãµes solicitadas para revisÃ£o do plano
   */
  private static async extractAlteracoesPlano(message: string, sessionId: string): Promise<Partial<PlanoAulaData>> {
    const alteracoes: Partial<PlanoAulaData> = {};
    const msg = message.toLowerCase();

    // Detectar alteraÃ§Ã£o de dificuldade
    if (msg.includes('dificuldade') || msg.includes('fÃ¡cil') || msg.includes('mÃ©dio') || msg.includes('difÃ­cil') || 
        msg.includes('facil') || msg.includes('medio') || msg.includes('dificil')) {
      
      if (msg.includes('fÃ¡cil') || msg.includes('facil')) {
        alteracoes.nivelDificuldade = 'facil';
      } else if (msg.includes('mÃ©dio') || msg.includes('medio')) {
        alteracoes.nivelDificuldade = 'medio';
      } else if (msg.includes('difÃ­cil') || msg.includes('dificil')) {
        alteracoes.nivelDificuldade = 'dificil';
      }
    }

    // Detectar alteraÃ§Ã£o de ano
    const anos = ['1Âº', '2Âº', '3Âº', '4Âº', '5Âº', '6Âº', '7Âº', '8Âº', '9Âº', '1Â°', '2Â°', '3Â°', '4Â°', '5Â°', '6Â°', '7Â°', '8Â°', '9Â°'];
    for (const ano of anos) {
      if (msg.includes(ano)) {
        alteracoes.ano = ano + ' ano';
        break;
      }
    }

    // Detectar alteraÃ§Ã£o de tema (usar LLM para extrair tema mais complexo)
    if (msg.includes('tema') || msg.includes('assunto') || msg.includes('conteÃºdo') || msg.includes('matÃ©ria')) {
      try {
        const { OpenAIService } = await import('./openai');
        const temaExtraido = await OpenAIService.extractTemaFromMessage(message, sessionId);
        if (temaExtraido) {
          alteracoes.tema = temaExtraido;
        }
      } catch (error) {
        ChatLogger.logError(sessionId, error as Error, { context: 'extract_tema', message });
      }
    }

    return alteracoes;
  }

  /**
   * Gera mensagem de continuidade conversacional apÃ³s a geraÃ§Ã£o do plano
   */
  private static async generatePostPlanContinuationMessage(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `VocÃª Ã© a ANE, assistente pedagÃ³gica. O professor acabou de receber um plano de aula completo.

Dados do plano gerado:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- NÃ­vel: ${data.nivelDificuldade || 'mÃ©dio'}

Gere uma mensagem de continuidade conversacional que:
1. Parabenize o professor pelo plano criado
2. Encoraje a reflexÃ£o sobre a prÃ¡tica pedagÃ³gica
3. OfereÃ§a suporte para prÃ³ximos passos
4. Seja acolhedora e motivadora
5. Mencione as opÃ§Ãµes de continuidade (ajustes, PDF, novos planos, etc.)

A mensagem deve ser natural, conversacional e incentivar o professor a continuar interagindo.

Exemplo de tom:
"Que plano incrÃ­vel criamos juntos! ğŸ‰ 
Agora que vocÃª tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 
Posso te ajudar com ajustes, gerar o PDF, ou atÃ© mesmo criar um novo plano. 
O que vocÃª gostaria de fazer agora?"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'VocÃª Ã© a ANE, uma assistente pedagÃ³gica amigÃ¡vel e encorajadora.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 200,
        temperature: 0.7
      });

      return response.choices[0]?.message?.content || 
        `Que plano incrÃ­vel criamos juntos! ğŸ‰ 

Agora que vocÃª tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 

Posso te ajudar com:
ğŸ‘‰ğŸ½ **Ajustes** no plano (duraÃ§Ã£o, atividades, dificuldade)
ğŸ‘‰ğŸ½ **Gerar PDF** para compartilhar
ğŸ‘‰ğŸ½ **Criar novo plano** para outro tema
ğŸ‘‰ğŸ½ **Sugerir atividades** complementares
ğŸ‘‰ğŸ½ **Tirar dÃºvidas** pedagÃ³gicas

O que vocÃª gostaria de fazer agora? ğŸ˜Š`;

    } catch (error) {
      console.error('âŒ Erro ao gerar mensagem de continuidade:', error);
      return `Que plano incrÃ­vel criamos juntos! ğŸ‰ 

Agora que vocÃª tem tudo estruturado, que tal refletirmos sobre como implementar na sua turma? 

Posso te ajudar com:
ğŸ‘‰ğŸ½ **Ajustes** no plano (duraÃ§Ã£o, atividades, dificuldade)
ğŸ‘‰ğŸ½ **Gerar PDF** para compartilhar
ğŸ‘‰ğŸ½ **Criar novo plano** para outro tema
ğŸ‘‰ğŸ½ **Sugerir atividades** complementares
ğŸ‘‰ğŸ½ **Tirar dÃºvidas** pedagÃ³gicas

O que vocÃª gostaria de fazer agora? ğŸ˜Š`;
    }
  }

  /**
   * Gera sugestÃµes de continuidade amigÃ¡veis apÃ³s a geraÃ§Ã£o do PDF
   */
  private static async generateContinuitySuggestions(data: PlanoAulaData, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `VocÃª Ã© a ANE, assistente pedagÃ³gica. O professor acabou de gerar o PDF do seu plano de aula.

Dados do plano:
- Ano: ${data.ano}
- Tema: ${data.tema || data.habilidadeBNCC}
- NÃ­vel: ${data.nivelDificuldade || 'mÃ©dio'}

Gere sugestÃµes de continuidade amigÃ¡veis e prÃ¡ticas que:
1. Sejam especÃ­ficas para o tema e ano do plano
2. OfereÃ§am atividades complementares concretas
3. Sugiram projetos interdisciplinares relevantes
4. Proponham estratÃ©gias de aprofundamento
5. Sejam fÃ¡ceis de implementar

Formate como uma conversa natural, nÃ£o como uma lista formal. Seja encorajadora e mostre entusiasmo pelas possibilidades.

Exemplo de tom:
"Que legal que vocÃª tem o PDF! ğŸ“„âœ¨ 

Agora que o plano estÃ¡ pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

ğŸ¨ **Projeto interdisciplinar**: Que tal conectar com Artes criando... [sugestÃ£o especÃ­fica]

ğŸ”¬ **Atividade prÃ¡tica**: Uma experiÃªncia simples que os alunos vÃ£o adorar Ã©... [sugestÃ£o especÃ­fica]

ğŸ“š **Leitura complementar**: Para aprofundar, sugiro... [sugestÃ£o especÃ­fica]

O que vocÃª acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa?"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'VocÃª Ã© a ANE, uma assistente pedagÃ³gica criativa e encorajadora que ama sugerir atividades prÃ¡ticas.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 300,
        temperature: 0.8
      });

      return response.choices[0]?.message?.content || 
        `Que legal que vocÃª tem o PDF! ğŸ“„âœ¨ 

Agora que o plano estÃ¡ pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

ğŸ¨ **Projeto interdisciplinar**: Que tal conectar com outras Ã¡reas do conhecimento?

ğŸ”¬ **Atividade prÃ¡tica**: Uma experiÃªncia simples que os alunos vÃ£o adorar!

ğŸ“š **Leitura complementar**: Para aprofundar o tema de forma divertida!

O que vocÃª acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? ğŸ˜Š`;

    } catch (error) {
      console.error('âŒ Erro ao gerar sugestÃµes de continuidade:', error);
      return `Que legal que vocÃª tem o PDF! ğŸ“„âœ¨ 

Agora que o plano estÃ¡ pronto, que tal pensarmos em como dar continuidade a esse tema? 

Para o ${data.ano} trabalhando com ${data.tema || data.habilidadeBNCC}, eu sugiro algumas ideias que podem complementar perfeitamente:

ğŸ¨ **Projeto interdisciplinar**: Que tal conectar com outras Ã¡reas do conhecimento?

ğŸ”¬ **Atividade prÃ¡tica**: Uma experiÃªncia simples que os alunos vÃ£o adorar!

ğŸ“š **Leitura complementar**: Para aprofundar o tema de forma divertida!

O que vocÃª acha? Alguma dessas ideias te anima? Ou prefere que eu ajude com outra coisa? ğŸ˜Š`;
    }
  }

  /**
   * Gera sugestÃµes de temas baseadas no ano escolar
   */
  private static async generateThemeSuggestions(ano: string, sessionId: string): Promise<string> {
    try {
      const openai = await import('openai');
      const client = new openai.default({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const prompt = `VocÃª Ã© uma assistente pedagÃ³gica especializada em sugestÃµes de temas para planos de aula.

O professor estÃ¡ criando um plano de aula para o ${ano} e pediu sugestÃµes de tema.

Gere 5 sugestÃµes de temas interessantes e adequados para o ${ano}, considerando:
- A faixa etÃ¡ria dos alunos
- Os interesses tÃ­picos dessa idade
- A relevÃ¢ncia pedagÃ³gica
- A possibilidade de atividades prÃ¡ticas e engajantes

Formate a resposta de forma conversacional e acolhedora, como se fosse a ANE falando.

Exemplo de formato:
"Que legal que vocÃª quer sugestÃµes! ğŸ’¡ Aqui estÃ£o algumas ideias interessantes para o ${ano}:

1. [Tema 1] - [Breve explicaÃ§Ã£o do porquÃª Ã© interessante]
2. [Tema 2] - [Breve explicaÃ§Ã£o do porquÃª Ã© interessante]
3. [Tema 3] - [Breve explicaÃ§Ã£o do porquÃª Ã© interessante]
4. [Tema 4] - [Breve explicaÃ§Ã£o do porquÃª Ã© interessante]
5. [Tema 5] - [Breve explicaÃ§Ã£o do porquÃª Ã© interessante]

Qual desses temas te chama mais atenÃ§Ã£o? Ou se preferir, pode me dizer outro tema que vocÃª tem em mente! ğŸ˜Š"`;

      const response = await client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'VocÃª Ã© a ANE, uma assistente pedagÃ³gica amigÃ¡vel e experiente.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 400,
        temperature: 0.7
      });

      return response.choices[0]?.message?.content || 
        `Que legal que vocÃª quer sugestÃµes! ğŸ’¡ Aqui estÃ£o algumas ideias interessantes para o ${ano}:

1. **FraÃ§Ãµes e decimais** - Um tema super prÃ¡tico que os alunos usam no dia a dia
2. **Sistema solar** - Sempre fascina as crianÃ§as e permite muitas atividades criativas
3. **Ciclo da Ã¡gua** - Tema visual e interativo, perfeito para experimentos
4. **HistÃ³ria do Brasil** - ConteÃºdo rico e importante para a formaÃ§Ã£o cidadÃ£
5. **Animais e habitats** - Tema que desperta curiosidade e permite pesquisas

Qual desses temas te chama mais atenÃ§Ã£o? Ou se preferir, pode me dizer outro tema que vocÃª tem em mente! ğŸ˜Š`;

    } catch (error) {
      console.error('âŒ Erro ao gerar sugestÃµes de tema:', error);
      return `Que legal que vocÃª quer sugestÃµes! ğŸ’¡ Aqui estÃ£o algumas ideias interessantes para o ${ano}:

1. **FraÃ§Ãµes e decimais** - Um tema super prÃ¡tico que os alunos usam no dia a dia
2. **Sistema solar** - Sempre fascina as crianÃ§as e permite muitas atividades criativas
3. **Ciclo da Ã¡gua** - Tema visual e interativo, perfeito para experimentos
4. **HistÃ³ria do Brasil** - ConteÃºdo rico e importante para a formaÃ§Ã£o cidadÃ£
5. **Animais e habitats** - Tema que desperta curiosidade e permite pesquisas

Qual desses temas te chama mais atenÃ§Ã£o? Ou se preferir, pode me dizer outro tema que vocÃª tem em mente! ğŸ˜Š`;
    }
  }

  /**
   * Extrai o conteÃºdo do plano de aula da mensagem
   */
  private static extractPlanoContent(message: string): string | null {
    try {
      // Encontrar onde termina o plano e comeÃ§am os prÃ³ximos passos
      const nextStepsIndex = message.indexOf('Prontinho! Aqui estÃ¡ o seu plano de aula');
      
      if (nextStepsIndex === -1) {
        // Se nÃ£o encontrar a seÃ§Ã£o de prÃ³ximos passos, retornar toda a mensagem
        return message;
      }

      // Retornar apenas o conteÃºdo do plano (antes dos prÃ³ximos passos)
      return message.substring(0, nextStepsIndex).trim();
    } catch (error) {
      console.error('âŒ Erro ao extrair conteÃºdo do plano:', error);
      return null;
    }
  }


  private static async handleContinuarIntent(sessionId: string, message: string): Promise<string> {
    const context = ConversationContextManager.getContext(sessionId);

    // Se jÃ¡ temos uma intenÃ§Ã£o ativa, continuar com ela
    if (context.currentIntent && context.currentIntent !== 'saudacao' && context.currentIntent !== 'continuar') {
      return this.generateResponseByIntent(message, sessionId, context.currentIntent);
    }

    // Se nÃ£o temos intenÃ§Ã£o ativa, analisar histÃ³rico para encontrar sugestÃ£o anterior
    const recentMessages = ConversationContextManager.getRecentUserMessages(sessionId, 5);
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);

    // Usar LLM para inferir o que o usuÃ¡rio quer continuar baseado no contexto
    const inferredIntent = await this.inferContinuationIntent(conversationHistory, sessionId);

    if (inferredIntent) {
      ConversationContextManager.updateIntent(sessionId, inferredIntent, 0.9);
      return this.generateResponseByIntent(message, sessionId, inferredIntent);
    }

    // Se nÃ£o conseguiu identificar contexto, gerar resposta contextual
    return await OpenAIService.generateContextualResponse(
      'continuar_sem_contexto',
      {
        message,
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );
  }

  private static async handleUnclearIntent(message: string, sessionId: string): Promise<string> {
    const msg = message.toLowerCase();
    const conversationHistory = ConversationContextManager.getConversationHistory(sessionId);
    const context = ConversationContextManager.getContext(sessionId);

    // Verificar se hÃ¡ um plano anterior e o usuÃ¡rio pode estar se referindo a ele
    const persistentContent = ConversationContextManager.getPersistentContent(sessionId);
    const hasPreviousPlan = persistentContent?.lastPlanoContent || persistentContent?.lastPlanejamentoContent;

    // Se o usuÃ¡rio diz que nÃ£o quer algo ou estÃ¡ negando
    if (msg.includes('nÃ£o quero') || msg.includes('nao quero') ||
        msg.includes('nÃ£o preciso') || msg.includes('nao preciso')) {
      return await OpenAIService.generateContextualResponse(
        'negacao',
        {
          message,
          conversationHistory: conversationHistory.map(msg => ({
            role: msg.sender === 'user' ? 'user' : 'assistant',
            content: msg.text
          }))
        },
        sessionId
      );
    }

    // Verificar se parece uma pergunta (tira-dÃºvidas)
    if (msg.includes('?') || msg.includes('como') || msg.includes('que') ||
        msg.includes('qual') || msg.includes('quando') || msg.includes('onde') ||
        msg.includes('por que') || msg.includes('porque')) {

      // Processar como tira-dÃºvidas
      return await OpenAIService.generateResponse(message, sessionId);
    }

    // Se hÃ¡ um plano anterior e a mensagem Ã© vaga, oferecer opÃ§Ãµes contextuais
    if (hasPreviousPlan && (msg.length < 20 || msg.includes('e agora') || msg.includes('o que') || msg.includes('como'))) {
      return `Entendi! Vejo que vocÃª tem um plano anterior. O que vocÃª gostaria de fazer agora?

ğŸ‘‰ğŸ½ **Gerar PDF** do plano (digite "manda o plano" ou "gerar pdf")
ğŸ‘‰ğŸ½ **Criar novo plano** de aula
ğŸ‘‰ğŸ½ **Ajustar o plano** anterior (alterar dificuldade, ano ou tema)
ğŸ‘‰ğŸ½ **Sugerir atividades** complementares
ğŸ‘‰ğŸ½ **Tirar dÃºvidas** pedagÃ³gicas

Qual opÃ§Ã£o te interessa? ğŸ˜Š`;
    }

    // Fallback geral - intenÃ§Ã£o nÃ£o clara
    return await OpenAIService.generateContextualResponse(
      'unclear_intent',
      {
        message,
        conversationHistory: conversationHistory.map(msg => ({
          role: msg.sender === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
      },
      sessionId
    );
  }
}